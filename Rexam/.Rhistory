table<-rbind(table,t)
nexturl<-"#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > div > a.next"
nextpage<-remDr$findElement(using="css selector",nexturl)
nextpage$clickElement()
Sys.sleep(1)
library(RSelenium)
remDr <- remoteDriver(remoteServerAddr = "localhost" ,
port = 4445, browserName = "chrome")
remDr$open()
remDr$navigate("http://gs25.gsretail.com/gscvs/ko/products/event-goods")
Sys.sleep(1)
tpo<-remDr$findElement(using="css selector","#TWO_TO_ONE")
tpo$clickElement()
table<-NULL
Sys.sleep(2)
goodsn<-remDr$findElements(using="css selector","#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > ul > li > div > p.tit")
goodsp<-remDr$findElements(using="css selector","#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > ul > li > div > p.price")
goodsname<-sapply(goodsn,function(x){x$getElementText()})
goodsprice<-sapply(goodsp,function(x){x$getElementText()})
goodsprice<-gsub("[,원]","",goodsprice)
t<-cbind(goodsname,goodsprice)
table<-rbind(table,t)
index=0
oldurl<-0
repeat{
oldurl<-remDr$findElement(using="css selector","#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > div > span > a.on")
oldurl<-as.numeric(oldurl$getElementText())
index<-index+1
if(index!=oldurl)
break;
goodsn<-remDr$findElements(using="css selector","#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > ul > li > div > p.tit")
goodsp<-remDr$findElements(using="css selector","#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > ul > li > div > p.price")
goodsname<-sapply(goodsn,function(x){x$getElementText()})
goodsprice<-sapply(goodsp,function(x){x$getElementText()})
goodsprice<-gsub("[,원]","",goodsprice)
t<-cbind(goodsname,goodsprice)
table<-rbind(table,t)
nexturl<-"#contents > div.cnt > div.cnt_section.mt50 > div > div > div:nth-child(5) > div > a.next"
nextpage<-remDr$findElement(using="css selector",nexturl)
nextpage$clickElement()
Sys.sleep(1)
}
write.csv(table,"gs25_twotoone.csv",fileEncoding = "UTF-8")
# 텍스트 분석
# 한국어 형태소 분석 패키지 설치
# Rtools 설치
# https://cran.r-project.org/bin/windows/Rtools/index.html
install.packages("Sejong")
install.packages("hash")
install.packages("tau")
install.packages("devtools") # 시간이 오래 걸림
# github 버전 설치
# 64bit 에서만 동작합니다.
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))
library(KoNLP)
# 일부 패키지의 버전 문제로 업데이트 설치 요구함. 1번 선택하고 계속 진행할 것
useSejongDic()
library(KoNLP)
Sys.getenv("JAVA_HOME")
SimplePos09("오늘 비가 내린다.") # 9가지 품사로 형태소 분석
SimplePos22("오늘 비가 내린다.") # 22가지 품사로 형태소 분석
extractNoun("오늘 비가 내린다.") # 명사만 추출
extractNoun("아버지가방에들어가셨다.", autoSpacing = T)
library(KoNLP)
word_data <- readLines("data/애국가(가사).txt")
word_data
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
word_data3 <- extractNoun(word_data)
word_data3
extractNoun("할리우드 톱스타 레오나르도 디카프리오는 '선행 전도사'다운 행보를 이어갔다.")
buildDictionary(user_dic=data.frame("디카프리오", "ncn"),replace_usr_dic = T)
extractNoun("할리우드 톱스타 레오나르도 디카프리오는 '선행 전도사'다운 행보를 이어갔다.")
undata <- unlist(word_data3)
undata
add_words <- c("백두산", "남산", "철갑", "가을", "달")
buildDictionary(user_dic=data.frame(add_words, rep("ncn")), replace_usr_dic=T)
word_data3 <- extractNoun(word_data)
word_data3
undata <- unlist(word_data3)
undata
word_table <- table(undata)
word_table
undata2 <- Filter(function(x) {nchar(x) >= 2}, undata)
word_table2 <- table(undata2)
word_table2
undata2 <- Filter(function(x) {nchar(x) >= 2}, undata)
word_table2 <- table(undata2)
word_table2
final <- sort(word_table2, decreasing = T)
head(final, 10)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
SimplePos09("대한민국의 영토는 한반도와 그 부속도서로 한다")
SimplePos22("대한민국의 영토는 한반도와 그 부속도서로 한다")
# 워드 클라우드
install.packages("wordcloud")
install.packages("wordcloud2")
library(wordcloud)
library(wordcloud2)
(words <- read.csv("data/wc.csv"))
head(words)
?windowsFonts
windowsFonts(lett=windowsFont("휴먼옛체"))
windowsFonts(dog=windowsFont("THE개이득"))
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq,family="lett")
wordcloud(words$keyword, words$freq,family="dog")
wordcloud(words$keyword, words$freq)
(words <- read.csv("data/wc.csv"))
head(words)
wordcloud(words$keyword, words$freq,family="lett")
(words <- read.csv("data/wc.csv"))
head(words)
?windowsFonts
windowsFonts(lett=windowsFont("휴먼옛체"))
windowsFonts(dog=windowsFont("THE개이득"))
wordcloud(words$keyword, words$freq)
library(wordcloud)
library(wordcloud2)
(words <- read.csv("data/wc.csv"))
head(words)
?windowsFonts
windowsFonts(lett=windowsFont("휴먼옛체"))
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq,family="lett")
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
library(wordcloud)
library(wordcloud2)
(words <- read.csv("data/wc.csv"))
head(words)
gc()
library(wordcloud)
library(wordcloud2)
(words <- read.csv("data/wc.csv"))
head(words)
windowsFonts(lett=windowsFont("휴먼옛체"))
windowsFonts(dog=windowsFont("THE개이득"))
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq,family="lett")
wordcloud(words$keyword, words$freq,family="dog")
wordcloud(words$keyword, words$freq)
wordcloud(words$keyword, words$freq,family="lett")
wordcloud(words$keyword, words$freq,family="lett")
wordcloud(words$keyword, words$freq,family="dog")
wordcloud(words$keyword, words$freq,family="dog")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(7))
head(words)
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud(words$keyword, words$freq,
min.freq = 2,
random.order = F,
rot.per = 0.5, scale = c(4, 1),
colors = rainbow(20), family="lett")
wordcloud2(words, fontFamily = "휴먼옛체")
wordcloud2(words,rotateRatio = 1)
wordcloud2(words, fontFamily = "휴먼옛체")
wordcloud2(words,rotateRatio = 1)
wordcloud2(words,rotateRatio = 0.5)
wordcloud2(words,rotateRatio = 0)
str(demoFreq)
wordcloud2(data = demoFreq) # str(demoFreq)
wordcloud2(data = demoFreq, shape = 'diamond')
wordcloud2(data = demoFreq, shape = 'star')
wordcloud2(data = demoFreq, shape = 'cardioid')
wordcloud2(data = demoFreq, shape = 'triangle-forward')
wordcloud2(data = demoFreq, shape = 'triangle')
result<-wordcloud2(data = demoFreq, shape = 'pentagon')
library(htmlwidgets)
saveWidget(result,"output/tmpwc1.html",selfcontained = T) #오동작
saveWidget(result,"output/tmpwc2.html",selfcontained = F)
htmltools::save_html(result,"output/tmpwc3.html")
head(demoFreq)
str(demoFreq)
wordcloud(names(final),final)
word_data <- readLines("data/애국가(가사).txt")
word_data
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
word_data3 <- extractNoun(word_data)
word_data3
add_words <- c("백두산", "남산", "철갑", "가을", "달")
buildDictionary(user_dic=data.frame(add_words, rep("ncn")), replace_usr_dic=T)
word_data3 <- extractNoun(word_data)
word_data3
undata <- unlist(word_data3)
undata
word_table <- table(undata)
word_table
undata2 <- Filter(function(x) {nchar(x) >= 2}, undata)
word_table2 <- table(undata2)
word_table2
final <- sort(word_table2, decreasing = T)
wordcloud(names(final),final)
wordcloud(names(final),final, min.freq = 1)
wordcloud2(final)
library(XML)
library(httr)
searchUrl<- "https://openapi.naver.com/v1/search/blog.xml"
Client_ID <- "izGsqP2exeThwwEUVU3x"
Client_Secret <- "WrwbQ1l6ZI"
query <- URLencode("봄")
url <- paste0(searchUrl, "?query=", query, "&display=100")
doc <- GET(url, add_headers("Content_Type" = "application/xml",
"X-Naver-client-Id" = Client_ID, "X-naver-Client-Secret" = Client_Secret))
# 블로그 내용에 대한 리스트 만들기
doc2 <- xmlParse(doc, encoding="UTF-8")
spring <- xpathSApply(doc2, "//item/description", xmlValue)
spring <- gsub("</?b>", "", spring)
spring <- gsub("&[a-z];", "", spring)
spring
word <- extractNoun(spring)
cdata <- unlist(word)
cdata <- Filter(function(x) {nchar(x) < 6 & nchar(x) >= 2} ,cdata)
wordcount <- table(cdata)
wordcount <- head(sort(wordcount, decreasing=T),30)
wordcount
?par
par(mar=c(1,1,1,1))
wordcloud(names(wordcount),freq=wordcount,scale=c(3,0.5),rot.per=0.35,min.freq=1,
random.order=F,random.color=T,colors=rainbow(20), family="dog")
par(mar=c(1,1,1,5))
wordcloud(names(wordcount),freq=wordcount,scale=c(3,0.5),rot.per=0.35,min.freq=1,
random.order=F,random.color=T,colors=rainbow(20), family="dog")
wordcloud(names(wordcount),freq=wordcount,scale=c(3,0.5),rot.per=0.35,min.freq=1,
random.order=F,random.color=T,colors=rainbow(20), family="dog")
data<-read.csv("output/movie_reviews3.csv",encoding = "UTF-8")
data<-head(sort(data,decreasing=T))
#1
data<-read.csv("output/movie_reviews3.csv",encoding = "UTF-8")
data<-sort(data,decreasing=T)
library(XML)
library(httr)
searchUrl<- "https://openapi.naver.com/v1/search/blog.xml"
Client_ID <- "izGsqP2exeThwwEUVU3x"
Client_Secret <- "WrwbQ1l6ZI"
query <- URLencode("봄")
url <- paste0(searchUrl, "?query=", query, "&display=100")
doc <- GET(url, add_headers("Content_Type" = "application/xml",
"X-Naver-client-Id" = Client_ID, "X-naver-Client-Secret" = Client_Secret))
# 블로그 내용에 대한 리스트 만들기
doc2 <- xmlParse(doc, encoding="UTF-8")
spring <- xpathSApply(doc2, "//item/description", xmlValue)
spring <- gsub("</?b>", "", spring)
spring <- gsub("&[a-z];", "", spring)
spring
data<-read.csv("output/movie_reviews3.csv",encoding = "UTF-8")
word<-extractNoun(data)
cdata<-unlist(word)
word<-extractNoun(data$vreview)
cdata<-unlist(word)
wordcount<-table(cdata)
wordcount<-head(sort(wordcount,decreasing=T),10)
View(wordcount)
wordcount<-table(cdata)
cdata<-unlist(word)
cdata
#1
data<-read.csv("output/movie_reviews3.csv",encoding = "UTF-8")
word<-extractNoun(data$vreview)
cdata<-unlist(word)
cdata
#1
data<-read.csv("output/movie_reviews3.csv")
word<-extractNoun(data$vreview)
cdata<-unlist(word)
cdata
wordcount<-table(cdata)
wordcount<-head(sort(wordcount,decreasing=T),10)
wordcount
names(wordcount)<-c("wname","wcount")
wordcount
wordcount<-table(cdata)
wordcount
wordcount<-NULL
wordcount<-table(cdata)
wordcount
wordcount<-NULL
#1
data<-read.csv("output/movie_reviews3.csv")
word<-extractNoun(data$vreview)
cdata<-unlist(word)
wordcount<-NULL
wordcount<-table(cdata)
wordcount<-head(sort(wordcount,decreasing=T),10)
wordcount
names(wordcount[2])<-c("wcount")
View(wordcount)
names(wordcount[2])<-c("wcount")
wordcount
names(wordcount)
wname<-unlist(word)
wordcount<-NULL
wordcount<-table(wname,wcount)
wordcount<-head(sort(wordcount,decreasing=T),10)
names(wordcount[2])<-c("wcount")
wordcount<-table(wname)
wordcount<-NULL
word<-extractNoun(data$vreview)
wname<-unlist(word)
wordcount<-table(wname)
wordcount<-head(sort(wordcount,decreasing=T),10)
wordcount
View(wordcount)
names(wordcount)
names(wordcount)[1]
table(wname)
wordcount<-head(sort(wordcount,decreasing=T),10)
wordcount
t(wordcount)
wordcount
View(wordcount)
wordcount<-NULL
table<-table(wname)
table<-head(sort(table,decreasing=T),10)
table
table[,1]
table[1]
table[2]
count(table[1])
value(table[1])
name(table[1])
names(table[1])
values(table)
wordcount<-data.frame(wname=names(table),wcount=as.numeric(table))
View(wordcount)
write.csv(wordcount,"output/movie_top_word.csv")
library(wordcloud2)
data2<-readlines("output/yes24.txt")
words<-gsub("[A-Za-Z]","",data2)
words<-gsub("[[:punct:]]","",words)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
wordcount<-sort(wordcount,decreasing=T)
result<-data.frame(names(wordcount),as.numeric(wordcount))
?readline
data2<-readlines("output/yes24.txt")
data2<-readLines("output/yes24.txt")
words<-gsub("[A-Za-Z]","",data2)
words<-gsub("[A-Z,a-Z]","",data2)
words<-gsub("[A-Z|a-Z]","",data2)
words<-gsub("[A-Z|a-z]","",data2)
words<-gsub("[[:punct:]]","",words)
word<-extractNoun(words)
cdata<-unlist(word)
cdata
View(cdata)
words<-gsub("[[:cntrl:]]\\d","",words)
words<-gsub("^[가-힣]","",data2)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
View(wordcount)
#1
library(KoNLP)
library(wordcloud2)
data2<-readLines("output/yes24.txt")
words<-gsub("^[가-힣]","",data2)
words<-gsub("[[:punct:]]","",words)
words<-gsub("\\d","",words)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
View(wordcount)
data2<-readLines("output/yes24.txt")
words<-gsub("^[가-힣]","",data2)
words<-gsub("[A-Z,a-z]","",words)
words<-gsub("[[:punct:]]","",words)
words<-gsub("\\d","",words)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
wordcount<-sort(wordcount,decreasing=T)
result<-data.frame(names(wordcount),as.numeric(wordcount))
wordcloud2(result,rotateRatio = 0.4)
wordcloud2(result,size=0.5,rotateRatio = 0.4)
htmltools::save_html(result,"output/yes24.html")
library(htmlwidgets)
htmltools::save_html(result,"output/yes24.html")
wordcloud2(result,size=0.7,rotateRatio = 0.4)
result2<-wordcloud2(result,size=0.7,rotateRatio = 0.4)
library(htmlwidgets)
htmltools::save_html(result2,"output/yes24.html")
?saveWidget
a<-c("가a이","abc","가나다")
a<-gsub("^[가-힣]","",a)
a
a<-c("가a이","abc","가나다")
> a<-gsub("^[가-힣]","",a)a
a<-c("가a이","abc","가나다")
a<-gsub("[^가-힣]","",a)
a
data2<-readLines("output/yes24.txt")
words<-gsub("[^가-힣]","",data2)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
wordcount<-sort(wordcount,decreasing=T)
result<-data.frame(names(wordcount),as.numeric(wordcount))
View(result)
View(wordcount)
word
data2<-readLines("output/yes24.txt")
words<-gsub("[^가-힣]\\s","",data2)
words
words<-gsub("\\d","",words)
words
library(KoNLP)
useSejongDic()
library(wordcloud2)
data2<-readLines("output/yes24.txt")
words<-gsub("[^가-힣]\\s","",data2)
#words<-gsub("[A-Z,a-z]","",words)
words<-gsub("[[:punct:]]","",words)
words<-gsub("\\d","",words)
word<-extractNoun(words)
cdata<-unlist(word)
cdata<-Filter(function(x){nchar(x)>=2 && nchar(x)<=4},cdata)
wordcount<-table(cdata)
wordcount<-sort(wordcount,decreasing=T)
View(wordcouont)
result<-data.frame(names(wordcount),as.numeric(wordcount))
par(mar=c(1,1,1,1))
result2<-wordcloud2(result,size=0.7,rotateRatio = 0.4)
library(htmlwidgets)
htmltools::save_html(result2,"output/yes24.html")
words<-gsub("[^가-힣]\\s","",data2)
words
